{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_kkQ-Kkuk3Q"
      },
      "source": [
        "# Week 3: Data Preparation and Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eReQmI4VuogB"
      },
      "source": [
        "This notebook covers the fundamental steps required to prepare a dataset for analysis. We will be using a modified, 'messy' version of the New York City Airbnb dataset to practice identifying and fixing common data quality issues.\n",
        "\n",
        "Throughout the notebook, you will see `...` in code blocks. These indicate areas where you need to provide the correct code to complete the task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "troubleshooting_md"
      },
      "source": [
        "### Setup and Troubleshooting\n",
        "\n",
        "If you encounter a `ModuleNotFoundError` despite installing packages, your notebook might be using a different Python environment than your terminal.\n",
        "\n",
        "Run the cells below to diagnose the issue and install libraries specifically for this notebook's active environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "troubleshooting_code",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c45dfa4-9061-4649-fe1b-93849190dadb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Active Python path: /usr/bin/python3\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# 1. Check which Python interpreter this notebook is using\n",
        "import sys\n",
        "print(f\"Active Python path: {sys.executable}\")\n",
        "\n",
        "# 2. Install dependencies directly into the active kernel environment\n",
        "%pip install pandas numpy matplotlib scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiE0oEXQu1aX"
      },
      "source": [
        "### Library Imports\n",
        "\n",
        "We use `pandas` for data manipulation, `numpy` for numerical operations, and `matplotlib` for basic plotting. We also include `sklearn` components to demonstrate how cleaning affects machine learning performance later in the session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "V-QEON5suV-0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08XwWVOTu9Kt"
      },
      "source": [
        "## Part 1: Dataset Loading and Initial Inspection\n",
        "\n",
        "The first step in any data project is loading the data and getting a high-level overview of its structure. We use the [read_csv](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) function for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxDoGN8mu_5h"
      },
      "outputs": [],
      "source": [
        "# Load the NYC Airbnb messy dataset\n",
        "df = pd.read_csv(...)\n",
        "print(\"Rows and columns loaded:\", df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inspect_intro"
      },
      "source": [
        "### Initial Inspection Tasks\n",
        "\n",
        "Before cleaning, we must identify which columns contain errors. Common points of failure include:\n",
        "1.  **Missing data (NaN/Null)**: These can cause mathematical operations to fail.\n",
        "2.  **Incorrect Data Types**: Numbers stored as strings cannot be used for calculations.\n",
        "3.  **Anomalies**: Unexpected values that don't match the rest of the column.\n",
        "\n",
        "Use the following methods to explore the data:\n",
        "- [head()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html): Review the first few rows to see the data format.\n",
        "- [info()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html): Check data types and identify columns with many missing values.\n",
        "- [isna().sum()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html): Get an exact count of missing values per column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inspect_head"
      },
      "outputs": [],
      "source": [
        "# Review the first five rows of the dataset\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inspect_info"
      },
      "outputs": [],
      "source": [
        "# Display columns and their respective data types\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inspect_nulls"
      },
      "outputs": [],
      "source": [
        "# Count missing values for each column\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "CPDML_uyDEtr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extra Inspection: look at the min, max, and average values for columns, to see if there are any anomalies\n",
        "..."
      ],
      "metadata": {
        "id": "uOFO7h5uC5sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extra Inspection: look at the unique values of the text ('object') columns, do these match what you would expect?\n",
        "..."
      ],
      "metadata": {
        "id": "SLxkjQxCDIDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PErs3ltWvAN9"
      },
      "source": [
        "## Part 2: Data Cleaning Procedures\n",
        "\n",
        "Now that we have seen the issues, we will apply specific cleaning techniques to fix them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "age_fill_header"
      },
      "source": [
        "### Handling Missing Values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One option is to remove these datapoints from the dataset using [dropna()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html)."
      ],
      "metadata": {
        "id": "4Ky6Zb6KDksR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove datapoints with any missing values (ensure to set inplace=False, as we will want to use missing values again below)\n",
        "..."
      ],
      "metadata": {
        "id": "rPVErShKDoQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rather than deleting every row with a missing value, which might significantly reduce the size of our dataset, we can fill them with a sensible default. This is known as imputation.\n",
        "\n",
        "We will use [fillna()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html) to address columns like 'availability_365' that frequently have empty entries."
      ],
      "metadata": {
        "id": "zZJEGq77DjgJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "age_fill"
      },
      "outputs": [],
      "source": [
        "# Replace missing availability values with the mean values\n",
        "df['availability_365'] = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "general_cleaning_header"
      },
      "source": [
        "### Handling Duplicates\n",
        "\n",
        "Duplicate rows often occur during data collection or when merging multiple files. They can falsely inflate counts and lead to inaccurate statistical results.\n",
        "\n",
        "Use [drop_duplicates()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html) to ensure each row in the dataset is unique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "remove_duplicates"
      },
      "outputs": [],
      "source": [
        "# Remove duplicate rows to ensure data uniqueness\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u7nQtGvvJDG"
      },
      "source": [
        "### Correcting Data Types\n",
        "\n",
        "In this dataset, the 'price' column should be numeric. However, it may contain characters or empty strings that cause it to be loaded as a generic 'object' type.\n",
        "\n",
        "The [to_numeric()](https://pandas.pydata.org/docs/reference/api/pandas.to_numeric.html) function allows us to force these values into numbers. Setting `errors='coerce'` will turn any invalid values into `NaN` so they can be handled later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BAlILtlvDkt"
      },
      "outputs": [],
      "source": [
        "# Convert the price column to a numeric data type\n",
        "df['price'] = pd.to_numeric(df['price'], errors=...)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the date column(s) to a datetime data type\n",
        "..."
      ],
      "metadata": {
        "id": "yN0TenprE5Bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0-RHQ4fvDxJ"
      },
      "source": [
        "### Text Standardization\n",
        "\n",
        "Categorical text data is often inconsistent. If one entry is 'BROOKLYN' and another is 'brooklyn', a computer will treat them as two different places. Standardizing text to all lowercase and removing extra spaces ensures consistency.\n",
        "\n",
        "Relevant methods:\n",
        "- [str.strip()](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.strip.html): Removes leading and trailing whitespace.\n",
        "- [str.lower()](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lower.html): Converts all characters to lowercase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwfvoZ3HvNTF"
      },
      "outputs": [],
      "source": [
        "# Clean the neighbourhood strings by removing whitespace\n",
        "df['neighbourhood'] = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "casing_fix"
      },
      "outputs": [],
      "source": [
        "# Standardize neighbourhood group names to lowercase\n",
        "df['neighbourhood_group'] = ..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# There are also spelling errors, edit the value using .at or .loc, and assigning the correct value!\n",
        "..."
      ],
      "metadata": {
        "id": "-Qvkt7yrEYGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Are there any other issues you can spot with the data?"
      ],
      "metadata": {
        "id": "rmNu8JkOFOIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix them!\n",
        "..."
      ],
      "metadata": {
        "id": "-sDtZnAMFRD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Processing for ML"
      ],
      "metadata": {
        "id": "YDmJOar-FiCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the cell below to import the necessary tools:\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler"
      ],
      "metadata": {
        "id": "iN1OdN7HF6y2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may want to process categorical columns using [one-hot encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) or [label encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html), depending on their type. Check the documentation for how to apply these!"
      ],
      "metadata": {
        "id": "eURUCbENFqAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical values\n",
        "..."
      ],
      "metadata": {
        "id": "up2MhHPzFw4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will likely also want to scale your numerical features, by [normalisation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) or [standardisation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)."
      ],
      "metadata": {
        "id": "PZ5J6wQUGTOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale numeric values\n",
        "..."
      ],
      "metadata": {
        "id": "H-KXg_q5GYwh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}